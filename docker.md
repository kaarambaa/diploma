# Docker

 Чтобы запустить приложение в контейнере Docker, вам прежде всего понадобится создать образ Docker используя `Dockerfile`. Поэтому, создадим два `Dockerfile`, по одному для каждой директории проекта.

 ## Docker images
 
 Чтобы получить необходимые зависимости, нам нужно выполнить следующий скрипт:
 ```
 coffee-shop/liberty/prepare.sh
 barista/liberty/prepare.sh
 ```
 Давайте начнем с приложения coffee-shop. Под `coffee-shop/` мы создадим `Dockerfile` со следующим содержимым:
 ```
 FROM open-liberty:20.0.0.3-full-java8-openj9

 COPY liberty/extension /liberty/usr/extension/
 COPY liberty/server.xml /config/

 COPY target/coffee-shop.war /config/dropins/
 ```
 Объявление образа после `FROM` определяет базовый образ для нашего приложения. Используем это в качестве отправной точки. Предположим пока что, что этот базовый образ уже включает Open Liberty - сервер приложений и среду выполнения Java.

 `/config` и `config/dropins` - директории внутри контейера, где мы можем размещать наши конфигурации и деплоить артефакты.

 Команда `COPY` копирует ресурсы с хоста в контейнер, таким образом добавляя их в получившийся образ. Файл `liberty/server.xml` содержит конфигурацию сервера для конкретного приложения, включая все необходимые особенности, которые мы хотим использовать в нашем сервисе. Поскольку мы деплоим только одно приложение на каждый из работающих серверов и, как следствие, контейнеров, конфигурация сервера используется исключительно для отдельно взятых приложений.

 Потратьте минуту и изучите файл `liberty/server.xml`. Мы вернемся к ниму несколько позже.

 Теперь, создадим `Dockerfile` для приложения `barista` в разделе `barista/`:

 ```
 FROM open-liberty:20.0.0.3-full-java8-openj9

 COPY liberty/extension /liberty/usr/extension/
 COPY liberty/server.xml /config/

 COPY target/barista.war /config/dropins/
 ```

 ## Building

 Чтобы создать образы, используем следующую команду Docker: `docker build -t <image>:<tag> .` *(включая точку в конце!)*

 Для приложения `coffee-shop` это будет выглядеть следующим образом:
 ```
 cd coffee-shop/
 docker build -t de.icr.io/cee-<your-name>-workshop/coffee-shop:1 .
 ```
 Имя образа (в данном случае - `de.icr.io/cee-<your-name>-workshop/coffee-shop:1`) неявно содержит местоположение реестра обзраов, имя образа и версию (или тег). Если образ с таким именем извлекается (`pull`), выгружается (`push`), скачивается (`download`) или загружается (`upload`) то Docker уже будет знать пункт назначения.

 Часть `de.icr.io/…` указывает использованный облачный сервис, имя пользователя и рабочее пространство.

 Теперь повторяем то же самое для приложения `barista`:

 ```
 cd ../barista/
 docker build -t de.icr.io/cee-<your-name>-workshop/barista:1 .
 ```

 Отлично! Теперь у нас есть два локальных образа для приложений `coffee-shop` и `barista`, которые мы можем запустить как Docker контейнеры.

 ## Running

 При желании, мы можем запустить созданные образы Docker локально, на своих собственных устройствах.

 Для этого, вам необходимо помнить, что приложение `coffee-shop` будет соединено с бэк-едном `barista`, поэтому необходимо сделать и разрешить доступ ко второму контейнеру. Если мы посмотрим на исходный код приложения `coffee-shop`, в частности на шлюз `barista`, мы заметим, что приложение просто подключится к `http: // barista: 9080` - имя хоста `barista`.

 Это будет возможно за счет того, что мы указали, что наши микросервисы будут работать в облачной среде, где мы можем управлять средой независимо от приложений. Таким образом, мы гарантируем, что наши приложения будут доступны под логическими именами `coffee-shop` и `barista`.

 Для локально работающего контейнера мы можем назначить имена запущенным контейнерам, которые разрешены в других контейнерах, работающих в той же локальной сети Docker. Для этого необходимо указать как имена контейнеров, так и сеть. Мы запускаем наши контейнеры следующим образом:
 ```
 docker run --rm -d \
   --name barista \
   --network dkrnet \
   de.icr.io/cee-<your-name>-workshop/barista:1

 docker run --rm -d \
   --name coffee-shop \
   --network dkrnet \
   -p 9080:9080 \
   de.icr.io/cee-<your-name>-workshop/coffee-shop:1
 ```
Эти команды запускают два наших приложения в виде контейнеров Docker. Параметр `--rm` удалит контейнеры после их остановки, `-d` запускает контейнеры в фоновом режиме, `--name` указывает логические имена контейнеров, `--network` гарантирует, что оба контейнера будут работать в правильной сети, а `-p ` направляют порты локальных контейнеров на локальный хост.

Два работающих контейнера теперь могут разрешать и получать доступ друг к другу по логическим именам контейнеров, что позволяет нашему приложению `coffee-shop` подключаться к бэкэнду и `barista`, используя имя хоста `barista`. 

### Реализация доступа к приложениям

Теперь мы можем получить доступ и простестировать запущенные микросервисы. Поскольку они коммуницируют через HTTP, можем использовать любой REST клиент на ваш выбор, например `curl`.

### Health check
 
 Мы могли бы просто запросить у приложения заказы кофе, отразившиеся в системе, но для нашей облачной среды нам может потребоваться более простой способ проверить, работает ли наше приложение. Поэтому создадим ресурс  для проверки состояния приложения. Мы можем сделать это, используя простые REST ресурсы, например, реализованные в JAX-RS. Также можно использовать MicroProfile Health для проверки работоспособности.

 Создадим класс под названием `HealthResource` в проектах `barista` и `coffee shop`:
 ``` JAVA
 import org.eclipse.microprofile.health.*;
 import javax.enterprise.context.ApplicationScoped;

 @Readiness
 @ApplicationScoped
 public class HealthResource implements HealthCheck {

     @Override
     public HealthCheckResponse call() {
         return HealthCheckResponse.named("barista").withData("barista", "ok").up().build();
     }
 }
 ```
 Аналогично создайте класс для `coffee-shop`.

 Готово! 

 Однако, если мы хотим, чтобы эти изменения были включены в наши работающие контейнеры, нам, конечно же, нужно пересобрать приложения и образы Docker.

 После запуска приложений мы сможем получить доступ к `coffee-shop` через локальный порт `9080` и стандартный MicroProfile Health resource:
 ```
 curl localhost:9080/coffee-shop/resources/orders
 ```

 ### Заказ кофе
 Этот запрос  выдаст нам спискок заказов в виде набора JSON файлов. Поскольку мы еще не создавали заказов то возвращенный массив будет пуст.

 Давайте изменим это и создадим запись о заказе кофе в системе.

 Если мы посмотрим на ресурс JAX-RS в приложении `coffee-shop`, то увидим, что для создания нового заказа на кофе нам нужно запостить (`POST`) JSON, содержащий тип кофе. Используя curl, это действие будет выглядеть следующим образом:
 ```JSON
 curl localhost:9080/coffee-shop/resources/orders -i -XPOST \
  -H 'Content-Type: application/json' \
  -d '{"type":"Espresso"}'
 ```
 `-XPOST` обозначает метод `POST` в HTTP протоколе, `-H` - HTTP заголовок, нужен для того, чтобы сервис определил, что получил на вход JSON файл, а `-d` - указывает на данные, которые мы отправляем как тело HTTP запроса. Отправляя данный запрос, мы расчитываем получить ответ  `201 Created`, сообщающи об успешном внесении заказа в систему.

 Мы можем проверить это дважды, снова запросив ресурс для всех заказов кофе, аналогично предыдущему, который теперь должен ответить массивом JSON, который содержит наш заказ.

 Если это так, поздравляю! Вы только что создали, запустили и вручную протестировали облачные микросервисы, работающие в контейнерах Docker.